{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
    "### Due: November 22 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
    "\n",
    "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "## Step 1: Data Input (4 marks)\n",
    "\n",
    "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected. \n",
    "\n",
    "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
    "\n",
    "**You cannot use a dataset that was used for a previous assignment or in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>DrugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  DrugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  DrugY"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset (1 mark)\n",
    "path = '/Users/robbie/Desktop/ensf611/Assignments/Assignment 4/drug200.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20316765",
   "metadata": {},
   "source": [
    "### Questions (3 marks)\n",
    "\n",
    "1. (1 mark) What is the source of your dataset?\n",
    "1. (1 mark) Why did you pick this particular dataset?\n",
    "1. (1 mark) Was there anything challenging about finding a dataset that you wanted to use?\n",
    "\n",
    "*ANSWER HERE*\n",
    "1. dataset source: https://www.kaggle.com/datasets/prathamtripathi/drug-classification\n",
    "2. I picked this particular dataset because it contained a combination of features/target variable that seemed as though it make for a interesting classification exercise.\n",
    "3. I found it challenging finding a dataset which had an obvious target variable to be used in a machine learning application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing (5 marks)\n",
    "\n",
    "The next step is to process your data. Implement the following steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "afc244d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age            0\n",
       "Sex            0\n",
       "BP             0\n",
       "Cholesterol    0\n",
       "Na_to_K        0\n",
       "Drug           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data (if needed)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70a8c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.355</td>\n",
       "      <td>DrugY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.043</td>\n",
       "      <td>DrugY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   BP  Cholesterol  Na_to_K   Drug  Sex_M\n",
       "0   23  2.0          1.0   25.355  DrugY      0\n",
       "1   47  0.0          1.0   13.093  drugC      1\n",
       "2   47  0.0          1.0   10.114  drugC      1\n",
       "3   28  1.0          1.0    7.798  drugX      0\n",
       "4   61  0.0          1.0   18.043  DrugY      0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BP_order = ['LOW','NORMAL','HIGH']\n",
    "Chol_order = ['NORMAL','HIGH']\n",
    "ord_BP = OrdinalEncoder(categories = [BP_order])\n",
    "ord_Chol = OrdinalEncoder(categories = [Chol_order])\n",
    "\n",
    "df['BP'] = ord_BP.fit_transform(df[['BP']])\n",
    "df['Cholesterol'] = ord_Chol.fit_transform(df[['Cholesterol']])\n",
    "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
    "df['Sex_M'] = df['Sex_M'].astype(int)\n",
    "\n",
    "features = ['Age', 'BP', 'Cholesterol', 'Na_to_K', 'Sex_M']\n",
    "target = 'Drug'\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "65d669f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c46b7",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "\n",
    "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why.\n",
    "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?\n",
    "\n",
    "*ANSWER HERE*\n",
    "1. There were no missing or null values is my dataset.  If there were missing values in a small number of rows, I would've have dropped the samples containing null values.  I would choose to drop the samples containing nulls rather than fill values because this is a relatively small dataset, I would be concerned that replacing any nulls might have a significant impact and skew the model.\n",
    "\n",
    "2. The dataset contains a combination of numerical and text values.  I had to use both ordinal and one hot encoding during the preprocessing of my data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "## Step 3: Implement Machine Learning Model (11 marks)\n",
    "\n",
    "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5558a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Random Forest Pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Logistic Regression Pipeline\n",
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# SVM Pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "982471f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grids\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__penalty': ['l1'],  \n",
    "    'classifier__solver': ['liblinear', 'saga']  \n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa0ec2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring metrics \n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "scoring = {\n",
    "    'f1_score': make_scorer(f1_score, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "53342356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/robbie/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create GridSearchCV instances for each algorithm with multiple scoring metrics\n",
    "grid_search_rf = GridSearchCV(rf_pipeline, param_grid_rf, cv=5, scoring=scoring, refit='f1_score')\n",
    "grid_search_lr = GridSearchCV(lr_pipeline, param_grid_lr, cv=5, scoring=scoring, refit='f1_score')\n",
    "grid_search_svm = GridSearchCV(svm_pipeline, param_grid_svm, cv=5, scoring=scoring, refit='f1_score')\n",
    "\n",
    "# Fit the models\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters based on F1\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_params_lr = grid_search_lr.best_params_\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "\n",
    "# Access the results for both scoring metrics\n",
    "results_rf = grid_search_rf.cv_results_\n",
    "results_lr = grid_search_lr.cv_results_\n",
    "results_svm = grid_search_svm.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4fe1a36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "F1 scores: [0.962, 0.976, 0.962, 0.976, 0.976, 0.976, 0.986, 0.976, 0.986]\n",
      "Best Parameters for Random Forest based on F1: {'classifier__max_depth': 15, 'classifier__n_estimators': 100}\n",
      "\n",
      "Logistic Regression Results:\n",
      "F1 scores: [0.327, 0.32, 0.849, 0.958, 0.993, 0.962]\n",
      "Best Parameters for Logistic Regression based on F1: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "\n",
      "SVM Results:\n",
      "F1 scores: [0.856, 0.175, 0.968, 0.893, 0.937, 0.943]\n",
      "Best Parameters for SVM based on F1: {'classifier__C': 1, 'classifier__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Print the results for best parameters and F1\n",
    "print(\"Random Forest Results:\")\n",
    "print(\"F1 scores:\", [round(n, 3) for n in results_rf['mean_test_f1_score']])\n",
    "print(\"Best Parameters for Random Forest based on F1:\", best_params_rf)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"F1 scores:\", [round(n, 3) for n in results_lr['mean_test_f1_score']])\n",
    "print(\"Best Parameters for Logistic Regression based on F1:\", best_params_lr)\n",
    "\n",
    "print(\"\\nSVM Results:\")\n",
    "print(\"F1 scores:\", [round(n, 3) for n in results_svm['mean_test_f1_score']])\n",
    "print(\"Best Parameters for SVM based on F1:\", best_params_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd7075",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Do you need regression or classification models for your dataset?\n",
    "1. (2 marks) Which models did you select for testing and why?\n",
    "1. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?\n",
    "\n",
    "*ANSWER HERE*\n",
    "1. My dataset requires classification models.\n",
    "2. I selected Logisitc Regression, SVM, and Random Forest for my dataset because I wanted to see how models of varying complexity would perform on this dataset. \n",
    "3. The Random Forest model performed the best which makes sense based on the theory discussed in the course because it combines an ensembles of individual models which can often provide better results when compared against indivdual models like Linear Regression and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "## Step 4: Validate Model (6 marks)\n",
    "\n",
    "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69e64c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate testing accuracy (1 mark)\n",
    "# Make predictions on the test set\n",
    "rf_test_predictions = grid_search_rf.predict(X_test)\n",
    "lr_test_predictions = grid_search_lr.predict(X_test)\n",
    "svm_test_predictions = grid_search_svm.predict(X_test)\n",
    "\n",
    "# Calculate F1 scores \n",
    "rf_f1 = f1_score(y_test, rf_test_predictions, average='macro')\n",
    "lr_f1 = f1_score(y_test, rf_test_predictions, average='macro')\n",
    "svm_f1 = f1_score(y_test, svm_test_predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "279f3074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.987918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.987918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.844933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Test F1 Score\n",
       "Random Forest            0.987918\n",
       "Logistic Regression      0.987918\n",
       "SVM                      0.844933"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(index = ['Random Forest','Logistic Regression', 'SVM'], columns=['Test F1 Score'])\n",
    "\n",
    "results.loc['Random Forest'] = {'Test F1 Score':rf_f1}\n",
    "results.loc['Logistic Regression'] = {'Test F1 Score':lr_f1}\n",
    "results.loc['SVM'] = {'Test F1 Score':svm_f1}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4529ba",
   "metadata": {},
   "source": [
    "\n",
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Which accuracy metric did you choose? \n",
    "1. (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
    "1. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. I chose F1 as the accuracy metric. \n",
    "2. The Random Forest and Logistic Regression models performed similar to part 3, however the SVM model performed worse than part 3 indicating that it did not generalize as well. \n",
    "3. The best models achieved an F1 score over 98% which I believe can be considered \"good enough\" for the context of this dataset.  A model which can predict which drug a patient is taking with a 98% accuracy I believe would be useful because a model like this could be used to validate the effectness of one drug over another.  This analysis could be improved by seeking out a larger dataset to improve the model further and to validate results on a larger testing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. My code was mainly sourced from the Lab 6 examples as well as other previous class examples. \n",
    "2. I completed the steps in the order laid out in the assignment template. \n",
    "3. I did not use any generative AI for this assignment. \n",
    "4. I had challenges with understanding the pipeline and grid search setup.  I used the lecture notes and class examples to gain a better understanding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "\n",
    "I enjoyed that there was more flexibility in this assignment which made it so I had to think harder about what steps were required and why I was doing them, as opposed to following a strict template.  I found it challenging setting up the pipelines and grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
